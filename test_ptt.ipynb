{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.ptt.cc/bbs/Gossiping/index.html\"\n",
    "\n",
    "my_header = {'cookie' : 'over18=1;'}\n",
    "\n",
    "response = requests.get(url, headers=my_header)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "\n",
    "soup = bs4.BeautifulSoup(response.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Re: [新聞] 顧腦麻女50年「社福神隱」！慈父不忍棉被\n",
      "\n",
      "\n",
      "Re: [新聞] 台幣狂升守不住！央行罕見發文：同舟共\n",
      "\n",
      "\n",
      "[問卦] 嚴白虎\n",
      "\n",
      "\n",
      "[爆卦] 大屯山助航站2點開始下雪了\n",
      "\n",
      "\n",
      "[爆卦] 比特幣瞬間暴跌兩千\n",
      "\n",
      "\n",
      "[新聞] 大屯山下雪啦!!!及時現況!!有SNG直播\n",
      "\n",
      "\n",
      "[公告] 八卦板板規(2020.11.21)\n",
      "\n",
      "\n",
      "[公告] 一月份置底閒聊區 \n",
      "\n",
      "\n",
      "[協尋] 2021/1/4 行車紀錄器 基隆路三段\n",
      "\n",
      "\n",
      "[協尋] 2021/1/5 行車紀錄器 重慶南路接近衡陽\n",
      "\n",
      "\n",
      "Fw: [徵求] 1/6竹北市三民路求行車記錄器\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titles = soup.find_all('div', 'title')\n",
    "\n",
    "for i in titles:\n",
    "    print(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#爬表特版的圖片，儲存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import datetime\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "ptt_url = \"https://www.ptt.cc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_webpage(url):\n",
    "    res = requests.get(url, cookies = {'over18':'1'})\n",
    "    if res.status_code != 200:\n",
    "        print(\"Invalid URL!!\", res.url)\n",
    "        return None\n",
    "    else:\n",
    "        return res.text\n",
    "    \n",
    "    \n",
    "def get_articles(page, date):\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    paging_dev = soup.find('div', 'btn-group btn-group-paging')\n",
    "    prevURL = paging_dev.find_all('a')[1]['href']\n",
    "    #prevURL = soup.select('.btn-group btn-group-paging >a')[1]['href']\n",
    "    \n",
    "    articles = []\n",
    "    \n",
    "    divs = soup.select('.rent')\n",
    "    for article in divs:\n",
    "        if article.find('div','date').text.strip() == date :\n",
    "            pushCount = 0\n",
    "            pushString = article.find('div', 'nrec').text\n",
    "            if pushString:\n",
    "                try:\n",
    "                    pushCount = int(pushString)\n",
    "                    \n",
    "                except ValueError:\n",
    "                    if pushString == \"爆\":\n",
    "                        pushCount = 99\n",
    "                    elif pushString.startswitch('X'):\n",
    "                        pushCount = -10\n",
    "                        \n",
    "            if article.find('a'):\n",
    "                title = article.find('a').text\n",
    "                herf = article.find('a')['herf']\n",
    "                author = article.find('div', 'author').text\n",
    "                articles.append({'title':title,\n",
    "                                 'herf':herf,\n",
    "                                 'pushCount':pushCount,\n",
    "                                 'author':author,\n",
    "                                })\n",
    "    return articles, prevURL\n",
    "        \n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "今天有 0 篇文章\n",
      "熱門文章(> 0 推):\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    allArticles = []\n",
    "    \n",
    "    currentPage = get_webpage(ptt_url+'/bbs/Beauty/index.html')\n",
    "    \n",
    "    todayRoot = datetime.date.today()\n",
    "    #today = todayRoot.strftime(\"%m/%d\").lstrip('0')\n",
    "    today = '1/07'\n",
    "    articles, prevURL = get_articles(currentPage, today)\n",
    "    print(articles)\n",
    "    while articles:\n",
    "        allArticles += articles\n",
    "        currentPage = get_webpage(ptt_url+prevURL)\n",
    "        articles, prevURL = get_articles(currentPage, today)\n",
    "        \n",
    "        \n",
    "    print('今天有', len(allArticles), '篇文章')\n",
    "    threshold = 0\n",
    "    print('熱門文章(> %d 推):' % (threshold))\n",
    "    \n",
    "    for article in allArticles:\n",
    "        if int(article['pushCount']) > threshold:\n",
    "            print(article['title'],ptt_url+article['href'])\n",
    "            \n",
    "            url = ptt_url+article['href']\n",
    "            newRequest = get_webpage(url)\n",
    "            soup = BeautifulSoup(newRequest, 'html')\n",
    "            \n",
    "            imgLinks = soup.findAll('a',{'href':re.compile('https:\\/\\/(imgur|i\\.imgur)\\.com\\/.*.jpg$')})\n",
    "            \n",
    "            folderName = article['title'].strip()\n",
    "            os.makedirs(folderName)\n",
    "            \n",
    "            if len(imgLinks) > 0:\n",
    "                try:\n",
    "                    for imgLink in imgLinks:\n",
    "                        print(imgLink['herf'])\n",
    "                        filename = imgLink['herf'].split(\"/\")[-1]\n",
    "                        urllib.request.urlretrieve(imgLink['herf'], os.path.join(folderName, filename))\n",
    "                except Exception as e :\n",
    "                    print(e)\n",
    "                                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "today = todayRoot.strftime(\"%m/%d\").lstrip('0')\n",
    "print(type(today))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[食記] 台南 樸九鼎風味火鍋168元吃到飽\n",
      " https://www.ptt.cc/bbs/Food/M.1610022096.A.505.html\n",
      "\n",
      "[食記] 新北 台南正宗碗粿肉粿\n",
      " https://www.ptt.cc/bbs/Food/M.1610022261.A.10F.html\n",
      "\n",
      "[食記] 台北萬華 阿寶師咖哩餃、老郭舖山東餅舖\n",
      " https://www.ptt.cc/bbs/Food/M.1610028812.A.D16.html\n",
      "\n",
      "[食記] 台北樂軒和牛專門店｜頂級和牛燒肉\n",
      " https://www.ptt.cc/bbs/Food/M.1610029159.A.54F.html\n",
      "\n",
      "[食記] 新北林口 浮島咖啡 時尚感風格咖啡\n",
      " https://www.ptt.cc/bbs/Food/M.1610029402.A.C47.html\n",
      "\n",
      "[廣宣] 南投日月潭 泰妃映月：泰菲印越南洋料理\n",
      " https://www.ptt.cc/bbs/Food/M.1610029903.A.AC0.html\n",
      "\n",
      "Fw: [食記] 高雄 福壽海鮮料理，海鮮、熱炒、酒品\n",
      " https://www.ptt.cc/bbs/Food/M.1610030188.A.F55.html\n",
      "\n",
      "[食記] 桃園中壢區。幸福家常便當\n",
      " https://www.ptt.cc/bbs/Food/M.1610030872.A.7A9.html\n",
      "\n",
      "[食記] 高雄 鹽埕區 阿進切仔麵 樸實的好味道\n",
      " https://www.ptt.cc/bbs/Food/M.1610031404.A.281.html\n",
      "\n",
      "[食記] 桃園中壢-多樣化手工窯烤披薩-大窯大擺\n",
      " https://www.ptt.cc/bbs/Food/M.1610034048.A.990.html\n",
      "\n",
      "[食記] 台北 城市愛玉 雙城街夜市中的檸檬愛玉冰\n",
      " https://www.ptt.cc/bbs/Food/M.1610034687.A.B92.html\n",
      "\n",
      "[食記] 台北 石‧撈麻辣鴛鴦鍋 牛舌、和牛吃到飽\n",
      " https://www.ptt.cc/bbs/Food/M.1610035207.A.A7A.html\n",
      "\n",
      "[食記] 新北 中和新井壽司日本料理\n",
      " https://www.ptt.cc/bbs/Food/M.1610046612.A.D71.html\n",
      "\n",
      "[食記] 台北 微風北車 頌丹樂 泰國米其林一星\n",
      " https://www.ptt.cc/bbs/Food/M.1610067424.A.CFE.html\n",
      "\n",
      "[食記] 基隆 今日早餐蔥油餅\n",
      " https://www.ptt.cc/bbs/Food/M.1610067556.A.670.html\n",
      "\n",
      "[食記] 台南》小古巴手做漢堡。有著濃濃異國風情\n",
      " https://www.ptt.cc/bbs/Food/M.1610070733.A.0FB.html\n",
      "\n",
      "[食記] 台南中西區 Nani麺/日式沾麵\n",
      " https://www.ptt.cc/bbs/Food/M.1610074199.A.E73.html\n",
      "\n",
      "[食記] 旺慢食餐酒館 義式餐點種類多美味無地雷\n",
      " https://www.ptt.cc/bbs/Food/M.1610074485.A.691.html\n",
      "\n",
      "[請益] 三媽分店品質怎麼落差這麼大?\n",
      " https://www.ptt.cc/bbs/Food/M.1610078312.A.5DC.html\n",
      "\n",
      "[食記] 基隆 美有計劃~基隆第一家網美義式餐廳\n",
      " https://www.ptt.cc/bbs/Food/M.1610079167.A.634.html\n",
      "\n",
      "[食記] 日本札幌 達摩成吉思汗烤肉\n",
      " https://www.ptt.cc/bbs/Food/M.1609941674.A.CA9.html\n",
      "\n",
      "[食記] 台北松山 我家小廚房\n",
      " https://www.ptt.cc/bbs/Food/M.1609942117.A.510.html\n",
      "\n",
      "[食記] 桃園中壢平鎮龍岡 必吃雲南料理 阿美米干\n",
      " https://www.ptt.cc/bbs/Food/M.1609942160.A.01C.html\n",
      "\n",
      "[食記] 常嚐廚房 | 新竹市巷弄私房無菜單料理\n",
      " https://www.ptt.cc/bbs/Food/M.1609943282.A.5EC.html\n",
      "\n",
      "[食記] 高雄 鹽埕區 蘭姐古早味傳統美食\n",
      " https://www.ptt.cc/bbs/Food/M.1609944012.A.57A.html\n",
      "\n",
      "[食記] 桃園中壢區。清蒸一口小肉圓\n",
      " https://www.ptt.cc/bbs/Food/M.1609947555.A.0ED.html\n",
      "\n",
      "[食記] 高雄 金鶴串場 一支只要10元的串燒與串炸\n",
      " https://www.ptt.cc/bbs/Food/M.1609948282.A.D52.html\n",
      "\n",
      "[食記] 台南 丰品1/2火鍋火烤兩吃吃到飽318元\n",
      " https://www.ptt.cc/bbs/Food/M.1609949074.A.96E.html\n",
      "\n",
      "[食記] 東京 つけめん さなだ 六厘舍的初代店長\n",
      " https://www.ptt.cc/bbs/Food/M.1609950077.A.C1C.html\n",
      "\n",
      "[食記] 台南 永康 金桃家草莓大福 抹茶大福好吃\n",
      " https://www.ptt.cc/bbs/Food/M.1609977880.A.47B.html\n",
      "\n",
      "[食記] 台北中正—達文西咖啡｜細啜土耳其壺帶渣咖啡濃厚滋味｜古亭\n",
      " https://www.ptt.cc/bbs/Food/M.1609985117.A.9CF.html\n",
      "\n",
      "[廣宣] 花蓮壽豐 鄉庭畜牧場(鄉庭驛站)\n",
      " https://www.ptt.cc/bbs/Food/M.1609989700.A.5FF.html\n",
      "\n",
      "[食記] 三峽 恩主公 中壢張記牛肉麵\n",
      " https://www.ptt.cc/bbs/Food/M.1609996575.A.06E.html\n",
      "\n",
      "[食記] 新北  北新莊十間健康料理分享\n",
      " https://www.ptt.cc/bbs/Food/M.1610001118.A.37C.html\n",
      "\n",
      "[食記] 澎湖｜吹吹風精品咖啡館 碼頭館\n",
      " https://www.ptt.cc/bbs/Food/M.1610002201.A.834.html\n",
      "\n",
      "[食記] 台北 老上海生煎包-超爆汁！雙色生煎包！\n",
      " https://www.ptt.cc/bbs/Food/M.1610008309.A.546.html\n",
      "\n",
      "[食記] 屏東》蕭家大院兔子親子餐廳\n",
      " https://www.ptt.cc/bbs/Food/M.1610009313.A.223.html\n",
      "\n",
      "[請益] 北市女性聚餐/幫女性友人慶生餐廳，燒肉\n",
      " https://www.ptt.cc/bbs/Food/M.1610010413.A.833.html\n",
      "\n",
      "[食記] 台北中山 TwoMonthsPerYear 很高標的甜點\n",
      " https://www.ptt.cc/bbs/Food/M.1610014900.A.B90.html\n",
      "\n",
      "[食記] [台南] 日升大飯店 ～不對外早餐自助吧\n",
      " https://www.ptt.cc/bbs/Food/M.1610016928.A.FEB.html\n",
      "\n",
      "[食記] 台南 堯平布朗尼專賣店\n",
      " https://www.ptt.cc/bbs/Food/M.1609901596.A.61B.html\n",
      "\n",
      "[食記] 高雄 無菜單料理-桑卓主廚\n",
      " https://www.ptt.cc/bbs/Food/M.1609902477.A.EB2.html\n",
      "\n",
      "[廣宣] 台中西屯 東海漁村\n",
      " https://www.ptt.cc/bbs/Food/M.1609904763.A.F94.html\n",
      "\n",
      "[請益] 台中咖啡廳-多人聚會\n",
      " https://www.ptt.cc/bbs/Food/M.1609908082.A.E56.html\n",
      "\n",
      "[食記] 美濃 家鄉味粄條 冬瓜封\n",
      " https://www.ptt.cc/bbs/Food/M.1609908638.A.4C8.html\n",
      "\n",
      "[食記] 新北板橋區。甕中甕炭火煨湯\n",
      " https://www.ptt.cc/bbs/Food/M.1609913649.A.ED1.html\n",
      "\n",
      "[食記] 推薦埔心美食 便宜又好吃的巷弄美食 香蕉\n",
      " https://www.ptt.cc/bbs/Food/M.1609914683.A.C60.html\n",
      "\n",
      "[討論] 有哪些外食算是低鈉的食物？\n",
      " https://www.ptt.cc/bbs/Food/M.1609921934.A.AFD.html\n",
      "\n",
      "[食記] 台北市信義區 霸味薑母鴨 松隆店\n",
      " https://www.ptt.cc/bbs/Food/M.1609922920.A.534.html\n",
      "\n",
      "[食記] 台北 中山麻糬伯-比臉大的粉粿！麻糬必吃\n",
      " https://www.ptt.cc/bbs/Food/M.1609923061.A.607.html\n",
      "\n",
      "[請益] 見女友家長餐廳請益(內有選手)\n",
      " https://www.ptt.cc/bbs/Food/M.1609923188.A.25E.html\n",
      "\n",
      "[情報] 新北汐止 阿梢越南小吃 平價大份量!\n",
      " https://www.ptt.cc/bbs/Food/M.1609926343.A.7E0.html\n",
      "\n",
      "[食記] 新竹 金福越式河粉 KING PHO BAR\n",
      " https://www.ptt.cc/bbs/Food/M.1609927407.A.2D2.html\n",
      "\n",
      "[請益]  求北市10人尾牙聚餐推薦\n",
      " https://www.ptt.cc/bbs/Food/M.1609929724.A.154.html\n",
      "\n",
      "[食記] 台中‧米其林一星‧Forchetta\n",
      " https://www.ptt.cc/bbs/Food/M.1609933957.A.520.html\n",
      "\n",
      "[食記] 台北中正 煮飯研究所 創意台味早午餐\n",
      " https://www.ptt.cc/bbs/Food/M.1609936995.A.EEE.html\n",
      "\n",
      "[食記] 新竹公園湖畔料亭｜日式懷舊庭園式景觀餐廳\n",
      " https://www.ptt.cc/bbs/Food/M.1609938814.A.04B.html\n",
      "\n",
      "[食記] 台南 好好吃肉韓式烤肉吃到飽299元起\n",
      " https://www.ptt.cc/bbs/Food/M.1609939926.A.B60.html\n",
      "\n",
      "Fw: [食記] 高雄 京華餐廳平津涮羊肉，羊肉爐、鍋物、熱炒\n",
      " https://www.ptt.cc/bbs/Food/M.1609939952.A.1E7.html\n",
      "\n",
      "[食記] 彰化 天公壇爌肉飯 家常味料理菜單種類多\n",
      " https://www.ptt.cc/bbs/Food/M.1609940874.A.74D.html\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url=\"https://www.ptt.cc/bbs/Food/index.html\"\n",
    "\n",
    "def get_all_href(url):\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "    \n",
    "    results = soup.select(\"div.title\")\n",
    "    #print(results)\n",
    "    for item in results:\n",
    "        a_item = item.select_one(\"a\")\n",
    "        #print(a_item)\n",
    "        title = item.text\n",
    "        #print(title)\n",
    "        if a_item:\n",
    "            print(title, 'https://www.ptt.cc'+ a_item.get('href'))\n",
    "        \n",
    "for page in range(1,4):\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text,\"html.parser\")\n",
    "    btn = soup.select('div.btn-group > a')\n",
    "    up_page_href = btn[3]['href']\n",
    "    next_page_url = 'https://www.ptt.cc' + up_page_href\n",
    "    url = next_page_url\n",
    "    get_all_href(url = url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "今天有 0 篇文章\n",
      "熱門文章(> 10 推):\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re\n",
    "import urllib.request\n",
    "import json\n",
    "\n",
    "\n",
    "PTT_URL = 'https://www.ptt.cc'\n",
    "\n",
    "\n",
    "def get_web_content(url):\n",
    "    resp = requests.get(url=url, cookies={'over18': '1'})\n",
    "    if resp.status_code != 200:\n",
    "        print('Invalid url: ' + resp.url)\n",
    "        return None\n",
    "    else:\n",
    "        return resp.text\n",
    "\n",
    "\n",
    "def get_articles(dom, date):\n",
    "    soup = BeautifulSoup(dom, 'html')\n",
    "\n",
    "    paging_dev = soup.find('div', 'btn-group btn-group-paging')\n",
    "    prev_url = paging_dev.find_all('a')[1]['href']\n",
    "\n",
    "    articles = []\n",
    "    divs = soup.find_all('div', 'r-ent')\n",
    "    for div in divs:\n",
    "        if div.find('div', 'date').text.strip() == date:\n",
    "            push_count = 0\n",
    "            push_str = div.find('div', 'nrec').text\n",
    "            if push_str:\n",
    "                try:\n",
    "                    push_count = int(push_str)\n",
    "                except ValueError:\n",
    "                    if push_str == '爆':\n",
    "                        push_count = 99\n",
    "                    elif push_str.startswith('X'):\n",
    "                        push_count = -10\n",
    "\n",
    "            if div.find('a'):\n",
    "                href = div.find('a')['href']\n",
    "                title = div.find('a').text\n",
    "                author = div.find('div', 'author').text if div.find('div', 'author') else ''\n",
    "                articles.append({\n",
    "                    'title': title,\n",
    "                    'href': href,\n",
    "                    'push_count': push_count,\n",
    "                    'author': author\n",
    "                })\n",
    "    return articles, prev_url\n",
    "\n",
    "\n",
    "def parse(dom):\n",
    "    soup = BeautifulSoup(dom, 'html.parser')\n",
    "    links = soup.find(id='main-content').find_all('a')\n",
    "    img_urls = []\n",
    "    for link in links:\n",
    "        if re.match(r'^https?://(i.)?(m.)?imgur.com', link['href']):\n",
    "            img_urls.append(link['href'])\n",
    "    return img_urls\n",
    "\n",
    "\n",
    "def save(img_urls, title):\n",
    "    if img_urls:\n",
    "        try:\n",
    "            folder_name = title.strip()\n",
    "            os.makedirs(folder_name)\n",
    "            for img_url in img_urls:\n",
    "                # e.g. 'http://imgur.com/9487qqq.jpg'.split('//') -> ['http:', 'imgur.com/9487qqq.jpg']\n",
    "                if img_url.split('//')[1].startswith('m.'):\n",
    "                    img_url = img_url.replace('//m.', '//i.')\n",
    "                if not img_url.split('//')[1].startswith('i.'):\n",
    "                    img_url = img_url.split('//')[0] + '//i.' + img_url.split('//')[1]\n",
    "                if not img_url.endswith('.jpg'):\n",
    "                    img_url += '.jpg'\n",
    "                file_name = img_url.split('/')[-1]\n",
    "                urllib.request.urlretrieve(img_url, os.path.join(folder_name, file_name))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "            \n",
    "\n",
    "def main():\n",
    "    current_page = get_web_content(PTT_URL + '/bbs/Beauty/index.html')\n",
    "    if current_page:\n",
    "        articles = []\n",
    "        date = time.strftime(\"%m/%d\").lstrip('0')\n",
    "        current_articles, prev_url = get_articles(current_page, date)\n",
    "        while current_articles:\n",
    "            articles += current_articles\n",
    "            current_page = get_web_content(PTT_URL + prev_url)\n",
    "            current_articles, prev_url = get_articles(current_page, date)\n",
    "        print('今天有', len(articles), '篇文章')\n",
    "        threshold = 10\n",
    "        print('熱門文章(> %d 推):' % (threshold))\n",
    "        for article in articles:\n",
    "            if int(article['push_count']) > threshold:\n",
    "                print('Collecting beauty from:', article)\n",
    "                page = get_web_content(PTT_URL + article['href'])\n",
    "                if page:\n",
    "                    img_urls = parse(page)\n",
    "                    save(img_urls, article['title'])\n",
    "                    article['num_image'] = len(img_urls)\n",
    "                \n",
    "        with open('data.json', 'w', encoding='utf-8') as file:\n",
    "            json.dump(articles, file, indent=2, sort_keys=True, ensure_ascii=False)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
